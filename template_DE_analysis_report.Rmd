---
title: 'RAVED: Differential Expression Analysis for Gene Expression Microarry Data -- GSE4917 dex_24hr vs baseline_24hr'
author: 'Mengyuan Kan (mengykan@upenn.edu)'
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: TRUE
    depth: 3
editor_options: 
  chunk_output_type: console
---
***

This report shows the differential analysis for gene expression microarry data from GEO study, including:

* Raw probe intensity normalization
* Differential expression
* Adjusting for batch effect

Input:

A pre-prepared phenotype file contains GEO_ID, Tissue, Disease and Treatment information.

Outputs:

* Gene differential expression result file(s) (.csv)
* A gene expression analysis report (.html)

Mannually change the variables for GEO ID (geo_id), data directory (datadir), result directory (resdir), tissue, disease/treatment status, and comparison conditions

```{r, var, eval=T, echo=F}
# GEO id
geo_id="GSE4917"
# direcotry stores GEO data
datadir="data"
# directory stores generated files
resdir="results"
# tissue
tissue="MCF10A-Myc"
# reference condition
con0="baseline_24hr"
# altered condition
con1="dex_24hr"
# treatment. Assign "comparison" if this column is used for DE.
treatment=c(con0,con1)
# disease. Assign "comparison" if this column is used for DE.
disease="healthy"
```

Manually change these variables according to dataset:
**Note that** four variables, platform (platform), geo_GPL (GPL id for analysis if the samples in the study were scanned on multiple platforms), usesuppl (whether to use supplementary data for DE analysis), and normdata (whether the expression matrix is normalized), need to be **manually** defined based on the QC reports. A shortname_func function is suggested to be updated.

```{r var2, eval=T, echo=F}
platform="Affymetrix"
geo_GPL=""
usesuppl=TRUE
normdata=FALSE
# The shortname_func function shortens the sample name shown in the plots. To start, define shortname_func <- function(x){x}
shortname_func <- function(x){gsub("^(.*).(cel|CEL).gz","\\1",x)} # remove .cel.gz or .CEL.gz from sample
```

Install the prerequisite R packages if they do not exist

* GEOquery 
* oligo
* limma
* sva
* annotate
* Bioconductor AnnotationData Packages: hgu133plus2.db, hgug4112a.db, hugene10sttranscriptcluster.db
* viridis (heatmap color)
* ggplot2
* gplots (heatmap2 plot)
* devtools (compute pca)
* pander


```{r pkg, eval=F, echo=F}
source("http://bioconductor.org/biocLite.R")
biocLite("GEOquery")
biocLite("preprocessCore")
biocLite("oligo")
biocLite("limma")
biocLite("sva")
biocLite("annotate")
biocLite("viridis")
install.packages("ggplot2")
install.packages("gplots")
install.packages("devtools")
install.packages("pander")
```

Load the necessary libraries

```{r lib, eval=T, echo=F, message=F, warning=F}
library(GEOquery)
library(oligo)
library(limma)
library(sva)
library(annotate)
library(viridis)
library(ggplot2)
library(gplots)
library(devtools)
library(preprocessCore)
library(pander)
```

## Obtain Phenotype and GEO Data

### Phenotype data preparation

```{r pheno_utility, eval=T, echo=F}
# The phenosub_func function subsets phenotypes based on the user defined variables
phenosub_func <- function(){
  pheno.sub=subset(pheno,(Tissue%in%tissue)&(Treatment%in%treatment)&(Disease%in%disease))
  pheno.sub=droplevels(pheno.sub)
  # assign comparison to "Status" column
  if (identical(sort(levels(pheno.sub$Treatment)),sort(c(con0,con1)))) {pheno.sub$Status=pheno.sub$Treatment} else {pheno.sub$Status=pheno.sub$Disease}
  pheno.sub$Status <-factor(pheno.sub$Status,levels=c(con0,con1))
  return(pheno.sub)
}

# The phenoqc_func function excludes outliers from phenotype file 
phenoqc_func <- function(outlier,pheno) {
  if (missing(outlier)) {pheno=subset(pheno, QC_Pass==1)} else {pheno=subset(pheno, Filename%in%outlier)}
  droplevels(pheno)
}

# The tbsum_func function generates summary of variables of interest
tbsum_func <- function(tb) {
  vars=c("Status", "ScanDate_Group") # variables of interest
  tb=as.data.frame(table(tb[,names(tb)%in%vars]))
  names(tb)[ncol(tb)]="Counts"
  return(tb)
}

# The infosumm_function generates summary of the comparison
infosumm_func <- function(pheno) {
  N_Condition0 <- sum(pheno$Status==con0) # count number of samples under condition 0
  N_Condition1 <- sum(pheno$Status==con1) # count number of samples under condition 1
  if (identical(sort(levels(pheno$Treatment)),sort(c(con0,con1)))) {
    App="GC"
    if (geo_GPL=="") {name=paste(geo_id,tissue,disease,con1,"vs",con0, sep="_")} else {{name=paste(geo_id,geo_GPL,tissue,disease,con1,"vs",con0, sep="_")}}
    Disease=disease
    Treatment=con1
  } else {
    App="Asthma"
    if (geo_GPL=="") {name=paste(geo_id,tissue,treatment,con1,"vs",con0, sep="_")} else {name=paste(geo_id,geo_GPL,tissue,treatment,con1,"vs",con0, sep="_")}
    Disease=con1
    Treatment=treatment
  }
  
  df <- data.frame(
    GEO_ID=geo_id,
    Tissue=tissue,
    App=App,
    Disease=Disease,
    Treatment=Treatment,
    N_Condition0=N_Condition0,
    N_Condition1=N_Condition1,
    Total=N_Condition0+N_Condition1,
    Unique_ID=name
  )
  return(list(df=df,name=name))
}
```

Read in pre-prepared phenotype data

```{r pheno_readin, eval=T, echo=F}
if (geo_GPL=="") {pheno_fn=paste0(resdir,"/",geo_id,"_Phenotype_withQC.txt")} else {pheno_fn=paste0(resdir,"/",geo_id,"_",geo_GPL,"_Phenotype_withQC.txt")}
# read in the pre-prepared phenotype data
if (!file.exists(pheno_fn)) {stop("The phenotype file does not exist. Please check!")} else {pheno <- read.table(pheno_fn, header=TRUE, sep="\t")}
```

Subset phenotypes based on the comparison variables. Check variables (before and after QC if outliers are detected).

```{r pheno_sub, eval=T, echo=F}
pheno.sub=phenosub_func()
outlier=as.character(pheno.sub$Filename)[pheno.sub$QC_Pass==0]
if (length(outlier)>0) {
  cat("Remove outlier(s)", outlier, "from phenotype file\n")
  pheno.of.interest=phenoqc_func(pheno=pheno.sub)
} else {pheno.of.interest=pheno.sub}
```

```{r pheno_sum, eval=T, echo=F, results="asis"}
if (length(outlier)>0) {
  pandoc.table(tbsum_func(tb=pheno.sub), split.tables=Inf, caption="Summary of subsetted samples without QC")
  pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples without QC")
} else {pandoc.table(tbsum_func(tb=pheno.of.interest), split.tables=Inf, caption="Summary of subsetted samples")}

# create a summary table for this comparison
pandoc.table(t(infosumm_func(pheno=pheno.of.interest)$df),split.tables=Inf, caption="Summary of the comparison")
```

Assign colours to status and scan date (if available)

```{r color, eval=T, echo=F}
# assign colours to comparison status
colour_status <- c("navy","red")
names(colour_status) <- c(con0,con1) # assign red to condition 1 and navy to condition 2
colour_status_list <- unlist(lapply(pheno.of.interest$Status,function(x){colour_status[x]}))
# assign colours to scan date
colours=c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02", "#A6761D", "#666666", "#8DD3C7", "#FFFFB3", "#BEBADA", "#FB8072", "#80B1D3", "#FDB462", "#B3DE69", "#FCCDE5", "#D9D9D9", "#BC80BD", "#CCEBC5", "#FFED6F") # first 8 colour names derived from Dark2, and last 12 names from Set3
if ("ScanDate_Group"%in%names(pheno)) {
  i=nlevels(pheno.of.interest$ScanDate_Group)
  colour_scandate <- colours[1:i]
  names(colour_scandate) <- levels(pheno.of.interest$ScanDate_Group) # colour to corresponding scan date
  colour_scandate_list <- unlist(lapply(pheno.of.interest$ScanDate_Group,function(x){colour_scandate[x]}))
}
```

### Gene expression data preparation

For data from Affymetrix platform, raw probe intensity data from supplementary files (usually .cel files) in GEO are downloaded and used for DE analysis. For data from Agilent platform, the intensity data is derived from GEO expression matrix.

Generate raw.data object using supplementary files (for Affymetrix data).

```{r suppldata_readin, eval=T, echo=F, message=F, warning=F, results="hide"}
# The suppdownload_func function downloads the supplimentary raw data files from GEO and unextract the zip file
suppldownload_func <- function() {
  getGEOSuppFiles(geo_id,baseDir=datadir) #download GEO files
  untar(paste0(datadir,"/",geo_id,"/",geo_id,"_RAW.tar"), exdir=paste0(datadir,"/",geo_id,"/data")) # extract the zip file
}

if (usesuppl) {
  # The sampall_func function obtains the supplementary filenames of all samples of interest
  sampall_func <- function() {basename(as.character(pheno$Filename))}
  # The rawall_func function obtains all files in the data directory with full path
  rawall_func <- function() {list.files(path=paste0(datadir,"/",geo_id,"/data"),pattern=paste(sampall_func(),collapse="|"),full.names=T)}

  # Download raw data files (e.g. .cel) if available.
  # Check whether the supplementary files already exist. Otherwise download from GEO
  samp_exist=basename(rawall_func())
  samp_need=sampall_func()

  if (length(samp_exist)==0) {
    suppldownload_func()
  } else {
    if (!identical(samp_exist,samp_need)) {suppldownload_func()}
  }
  samp_exist=basename(rawall_func()) # updated the existing samples
  if (!identical(samp_exist,samp_need)) {stop("The .cel files obtained from GEO do not include all the samples of interest")}
  
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.files=rawall_func()
  raw.data <- read.celfiles(raw.files)
}
```

Generate raw.data object using expression matrix from GEO (for platforms other than Affymetrix).

```{r geomatrix_readin, eval=T, echo=F, message=F, warning=F}
if (!usesuppl) {
# check if GEO matrix file exists
  geo_fn <- list.files(path=datadir)[grepl(geo_id,list.files(path=datadir))&grepl("matrix.txt.gz$",list.files(path=datadir))]
  if (length(geo_fn)==0) { # matrix files are alreadly downloaded
    gselms <- getGEO(geo_id, destdir=datadir, GSEMatrix = TRUE) # dowanload matrix file
   
    if (length(gselms)>1) {  # multiple platform
      message("This study was performed in multiple platforms")
      idx <- grep("GLP96|GPL570", attr(gselms, "names")) # only use data from GPL96
      gse <- gselms[[idx]]
    } else {gse <- gselms[[1]]}
  } else if (length(geo_fn)==1) {
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  } else { # multiple platform
    message("This study was performed in multiple platforms")
    geo_fn <- geo_fn[grep("GLP96|GPL570",geo_fn)]
    gse <- getGEO(filename=paste0(datadir,"/",geo_fn),GSEMatrix = TRUE)
  }
  # Read in the raw data and generate an object "raw.data" under the ExpressionFeatureSet (oligo class).
  raw.data=gse
}
```

Obtain raw.data.of.interest by subsetting raw.data based on the phenotype of interest

```{r sub_rawdata, eval=T, echo=F}
# The subdat_func function subsets data based on the phenotype of interest
subdat_func <- function(raw.data, pheno) {
  # subset raw.data based on the phenotype of interest
  raw.data=raw.data[,colnames(raw.data)%in%pheno$Filename]
  # assign phenotype data to raw expression data
  pData(raw.data) <- pheno
  row.names(pData(raw.data)) <- sampleNames(protocolData(raw.data))
  # check if the sample names derived from expression data match those in phenotype file
  if (!identical(row.names(pData(raw.data)),as.character(pheno$Filename))) {stop("The sample names derived from expression data do not match those in phenotype file. Please check!")}
  return(raw.data)
}
raw.data.of.interest=subdat_func(raw.data=raw.data, pheno=pheno.of.interest)
```

Show expression dataset features
```{r raw.data, eval=T, echo=F}
raw.data.of.interest
```

## Differential Gene Expression Analysis

### Normalize raw gene expression data

Normalize gene expression raw data using robust multi-array average (RMA) method (if supplementary data is available) or quantile normalize (if use expression matrix), unless the raw.data object is already normalized (based on the variable normdata).


If negative/zero intensity values are present, convert them to NAs.

```{r infinite_convert, eval=T, echo=F, fig.height=10, fig.width=12}
# check if any negative/zero intensity value in the expression data
if (any(apply(exprs(raw.data.of.interest),2,function(x){min(x,na.rm=T)})<=0)) {
  cat("Negative or zero intensity values are observed. Convert them to NA.\n")
}
exprs(raw.data.of.interest)=apply(exprs(raw.data.of.interest),2,function(x){replace(x,which(x<=0),NA)})
```

```{r rma, eval=T, echo=F, message=F, results="hide"}
if (usesuppl) {
  rma.data.of.interest = rma(raw.data.of.interest)
  cat("RMA normalization is used.\n")
} else {
  rma.data.of.interest=raw.data.of.interest
  if (!normdata) {exprs(rma.data.of.interest)=normalize.quantiles(log2(exprs(rma.data.of.interest)))
  cat("Quantile normalization and log2 transformation is used.\n")
  }
}
```

```{r rma_plot, eval=T, echo=F}
cols=colour_status_list
boxplot(raw.data.of.interest,target="core",col=cols,main="Raw Probe Intensities",xaxt="n") # view raw data
legend("topright",legend=names(colour_status),fill=colour_status)

if (!normdata) {
  boxplot(rma.data.of.interest,col=cols,main="Normalized Probe Intensities",xaxt="n") # view RMA-adjusted data
  legend("topright",legend=names(colour_status),fill=colour_status)
} else {cat("The raw data is already normalized")}
```


### Pairwise Comparison between Status

```{r limma_utility, eval=T, echo=F, results="asis"}
limma_func <- function() { # here only con0, con1 are used in comparisons. use a function to reduce the factor levels
  # Create a design model matrix for linear model. Fit a linear model using design matrix model.
  design = model.matrix(~ -1+factor(rma.data.of.interest$Status)) # create design model matrix
  colnames(design) = levels(factor(rma.data.of.interest$Status))
  fit = lmFit(rma.data.of.interest, design) # fit a linear model to estimate the fold changes and standard error
  # Create a contrast group and fit it in a linear model
  data.contrast = makeContrasts(contrasts=paste(c(con1,con0),collapse="-"),levels = design) # create a contrast group by comparing con1 vs con0
  fit2 = contrasts.fit(fit, data.contrast) # get the contrasts for samples of interest
  fit2 = eBayes(fit2) # adjust fit coefficients using an empirical Bayes moderation of standard errors
  return(list(design=design,data.contrast=data.contrast,fit2=fit2))
}

```

Fit a linear model to RMA log-intensity values, fit this model to a contrast matrix for the comparison of interest, and apply empirical Bayes smoothing to obtain more precise standard errors.

```{r limma, eval=T, echo=F, message=F, warning=F, results="asis"}
res_DE=limma_func()
fit2=res_DE$fit2
pandoc.table(data.frame(Sample=rma.data.of.interest$Sample,res_DE$design), split.tables=Inf, caption="A design model matrix for linear model")
pandoc.table(as.data.frame(res_DE$data.contrast), caption="A contract matrix for comparison")
contrast_table <- topTable(fit2, adjust="BH",num=Inf) # get full set of results for each hypothesis test
col.sel=c("logFC","AveExpr","t","P.Value","adj.P.Val","B") # select the columns of DE results
contrast_table <- data.frame(ID=row.names(contrast_table), contrast_table[,col.sel])
```

### Adjusting for Batch Effect

```{r sva_utility, eval=T, echo=F}
# The nbatch_func function obtains number of batches (scan date) in the data
nbatch_func <- function() {
  if (!"ScanDate_Group"%in%names(pData(rma.data.of.interest))) {nbatch=0} else {nbatch=nlevels(rma.data.of.interest$ScanDate_Group)}
}

# The svamod_func function creates full and null models, and Checks if the batch and comparison status are confounded
svamod_func <- function() {
  # Create a full model
  modBatch = model.matrix(~factor(rma.data.of.interest$Status)+factor(rma.data.of.interest$ScanDate_Group) ) # full model (adjustment variables and variables of interest)
  # Create a null model only including batch variables
  nullBatch =  model.matrix(~factor(rma.data.of.interest$ScanDate_Group)) # null model (adjustment variables only)
  # Check if the batch and comparison status are confounded
  if (class(try(solve(t(modBatch)%*%modBatch),silent=T))=="matrix") {batchadj=TRUE} else {batchadj=FALSE; message("The batch and comparison status are highly confounded")}
  # summary of the full model
  tb.fullmod <- as.data.frame(modBatch)
  names(tb.fullmod) <- c("Intercept",levels(rma.data.of.interest$Status)[-1],levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  # summary of the null model
  tb.nullmod <- as.data.frame(nullBatch)
  names(tb.nullmod) <- c("Intercept",levels(droplevels(rma.data.of.interest$ScanDate_Group))[-1])
  return(list(modBatch=modBatch, nullBatch=nullBatch, tb.fullmod=tb.fullmod, tb.nullmod=tb.nullmod, batchadj=batchadj))
}

# The batcherror_func function assigns a variable batcherror to decide whether to adjust for batch effect under various scenarios
batcherror_func <- function() {
  if (nbatch==0) {batcherror="zero"}
  else if (nbatch==1) {batcherror="one"}
  else {if (batchadj) {batcherror="no"} else {batcherror="correlate"}}
  return(batcherror)
}

# The batchadj_func function outputs table with batch effects adjusted p-values
batchadj_func <- function(batcherror=batcherror, contrast_table=contrast_table) {
  if (batcherror=="no") {
    modBatch=svamod_func()$modBatch
    nullBatch=svamod_func()$nullBatch
    pValuesBatch=f.pvalue(exprs(rma.data.of.interest), modBatch, nullBatch) # get batch effect-adjusted p-values
    qValuesBatch=p.adjust(pValuesBatch, method="BH") # get q-values
    tb.sva <- data.frame(ID=names(pValuesBatch),pValuesBatch,qValuesBatch)
    contrast_table <- merge(contrast_table, tb.sva, by="ID", all=TRUE)
  } else if (batcherror=="correlate") {
    contrast_table$pValuesBatch=contrast_table$qValuesBatch=rep(NA,nrow(contrast_table))
  } else {
    contrast_table$pValuesBatch=contrast_table$P.Value
    contrast_table$qValuesBatch=contrast_table$adj.P.Val
  }
  return(contrast_table)
}
```

Check whether to adjust for batch effect.

```{r sva_check, eval=T, echo=F}
nbatch=nbatch_func()
if (nbatch>1) {res_svamod=svamod_func();batchadj=res_svamod$batchadj}
batcherror=batcherror_func()
if (batcherror=="zero") {cat("No batch variable is present in the data.")} else if (batcherror=="one") {cat("Only one batch is present in the data.")} else if (batcherror=="correlate") {cat("The batch and the status are highly confounded (See the model matrix). Cannot ajust for batch effect.")}
```

Create a full model that includes all variables and a null model that only includes the batch variable. Note that as SVA computes the matrix x in t(batch model)%*%x=batch model, batch effect can be adjusted only when the solve function works.

```{r sva_mod, eval=T, echo=F, results="asis"}
if (nbatch>1) {
  pandoc.table(res_svamod$tb.fullmod, split.tables=Inf, caption="Full model matrix")
  pandoc.table(res_svamod$tb.nullmod, split.tables=Inf, caption="Null model matrix")
}
```


Compute F statistic p-values adjusted for batch effect. Q-values are obtained by the Benjamini-Hochberg method. If the batch and the status are correlated, assign NA to the batch adjusted p- and q-values. If there is no batch variable or only one batch, assign p- and q-values computed by limma to the batch adjusted p-values

```{r sva_tb, eval=T, echo=F, results="asis"}
contrast_table=batchadj_func(batcherror=batcherror, contrast_table=contrast_table)
pandoc.table(summary(contrast_table), split.tables=Inf, caption=paste0(con1, " vs. ", con0, " summary"))
```


### Assign Official Gene Symbol

Annotate official gene symbol to probes. Install the [R annotation database package](https://bioconductor.org/packages/3.7/data/annotation/) corresponding to your gene expression data. For any newly installed annotation databases, it can be added to the list anno_list reserved for future use.

```{r anno_list, eval=T, echo=F}
anno_list=list()
# Affymetrix
anno_list[["pd.hg.focus"]]="hgfocus.db"
anno_list[["pd.hg.u133a"]]="hgu133plus2.db"
anno_list[["pd.ht.hg.u133.plus.pm"]]= "hgu133plus2.db"
anno_list[["GPL96"]]="hgu133plus2.db"
anno_list[["pd.hg.u133.plus.2"]]="hgu133plus2.db"
anno_list[["pd.hugene.1.0.st.v1"]]="hugene10sttranscriptcluster.db"
anno_list[["pd.hugene.2.0.st.v1"]]="hugene20sttranscriptcluster.db"
anno_list[["GPL8300"]]="hgu95av2.db"
# Agilent
anno_list[["GPL6480"]]="hgug4112a.db"
# Illumina
anno_list[["GPL6947"]]="illuminaHumanv3.db"
anno_list[["GPL10558"]]="illuminaHumanv4.db"
```

```{r anno_utility, eval=T, echo=F, warning=F, message=F}
# install corresponding annotation database if it is not installed
anno_array=annotation(rma.data.of.interest)
cat("The platform used is", anno_array, "\n")
if (!anno_array%in%names(anno_list)) stop(paste0("The annotation database for array ", anno_array, " (", platform, " platform ) is not installed. Please find the annotation dabase in Bioconductor AnnotationData Packages\n"))
anno_lib=anno_list[[anno_array]] # use the annotation database
cat("The corresponding R annotation database package is", anno_lib,"\n")
# check if the annotation database is installed
if (!anno_lib%in%installed.packages()[,1]){source("http://bioconductor.org/biocLite.R"); biocLite(anno_lib)}
library(anno_lib, character.only=T)

geneannot_func <- function(tb) {
  anno_symbol=gsub(".db","SYMBOL",anno_lib) # The name of the R object mapping between probe id and gene symbol
  remove.pm <- function(x) {gsub("_PM", "", x)} # Assign official gene symbol using hgu133plus2.db package if anntoation is based on pd.hg.u133.plus.2. Note that the probe names have additional "PM"s in the results will be removed to match the names in the gene symbol package.
  if (anno_lib=="hgu133plus2.db") {tb$ID=sapply(as.character(tb$ID), remove.pm)} 
  tb$ID=as.character(tb$ID)
  tb$SYMBOL=sapply(as.character(tb$ID), function(x) mget(x, env=get(anno_symbol), ifnotfound=NA)[[1]])
  tb[order(tb$P.Value),]
}
```

```{r contrast_fn, eval=T, echo=F}
contrast_name=infosumm_func(pheno=pheno.of.interest)$name # adopt Unique_ID created in the information summary table
contrast_fn=paste0(resdir,"/", contrast_name, ".csv")
```

```{r anno_tb, eval=T, echo=F, warning=F, message=F}
contrast_table <- geneannot_func(tb=contrast_table)
write.csv(contrast_table, file=contrast_fn, row.names = FALSE)
```

```{r DE_readin, eval=T, echo=F}
if (file.exists(contrast_fn)) {contrast_fn=paste0(resdir,"/", contrast_name, ".csv")}
res=read.csv(contrast_fn)
```

## Gene Expression Results Visualization

### Volcano Plots

```{r vol_utility, eval=T, echo=F}
# The volplot_func function generates volcano plots
volplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else {          
    df <- df[!is.na(qval),] # remove NA values
    qval <- df[,qval_column]
    if (min(df[,qval_column])>=0.05) {
      df$sig <- "black" # assign colors to DE and non-DE genes
    } else {
      # assign colors to DE and non-DE genes
      df$sig <- rep(NA,nrow(df))
      df$sig[qval<0.05] <- "red"
      df$sig[qval>=0.05] <- "black"
    }
    df$sig <- as.factor(df$sig)
    color <- levels(df$sig)
    # log10 transformed q values
    df$logqval <- -log10(qval)
    diffgenes <- df$ID[qval<0.05] #Create list of all DEG's
    cat(length(diffgenes), "differentially expressed genes have been identified.")
    print(
    ggplot(df, aes(x = logFC, y = logqval, color=sig)) + geom_point() +
      theme_bw() +
      labs(title=title,x="logFC",y=paste0("-log10(",qval_column,")")) +
      scale_color_manual(values=color) +
      theme(legend.position="none")
    )
  }
}
```

Volcano plot (probes with a q-value <0.05 are present in red)

```{r vol, eval=T, echo=F, fig.height=4, fig.width=4.5}
for (qval in c("adj.P.Val","qValuesBatch")) {volplot_func(res, qval)}
```


### Histograms

```{r hist_utility, eval=T, echo=F}
# The histplot_func function generates histogram for p-value distributions
histplot_func <- function(df,qval_column,title) {
  if (missing(title)) {title=""}
  # get qvalue column
  qval <- df[,qval_column]
  if (all(is.na(qval))) {message("The batch and status are highly confounded. Batch effect is not adjusted.")} else{hist(qval,main=title,xlab=qval_column)}
}
```

Histograms of p-value distributions

```{r histplot, eval=T, echo=F, fig.width=4.5, fig.height=4}
for (pval in c("P.Value","pValuesBatch")) {histplot_func(res, pval)}
for (qval in c("adj.P.Val","qValuesBatch")) {histplot_func(res, qval)}
```

### Top 20 Differentially Expression Results

```{r top20_utility, eval=T, echo=F}
# The datreform_func function reformats the DE table
datreform_func <- function(dt,topnum=200) {
  dt=dt[order(dt$P.Value),]
  dt=dt[1:topnum,]
  round2 <- function(x){round(x,2)}
  dt[,c("logFC","AveExpr","t","B")] <- sapply(dt[,c("logFC","AveExpr","t","B")],round2)
  sciform <- function(x){format(x,scientific=TRUE,digits =2)}
  dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")] <- sapply(dt[,c("P.Value","adj.P.Val","pValuesBatch","qValuesBatch")],sciform)
  dt
}
```

Show top 20 probes sorted by un-adjusted p-values

```{r top20, eval=T, echo=F, results="asis"}
res <- datreform_func(dt=res)
rownames(res) <- NULL
pandoc.table(res[1:20,],split.tables=Inf)
```

### Boxplots for Top 6 Differentially Expressed Genes

This step helps to visualize and check the effect direction in the comparison.

```{r boxplot_utility, eval=T, echo=F}
# function for top gene boxplot
topgene_boxplot_func <- function(tb,colour,comp) { # comp: comparison status
  for (i in 1:nrow(tb)) {# top i probe in res
    if (missing(comp)) {comp=""}
    if (missing(colour)) {colour=colours[1]}
    probe_top <- tb$ID[i]
    gene_top <- tb$SYMBOL[i]
    row.names(rma.data.of.interest) <- gsub("_PM","",row.names(rma.data.of.interest))
    values=exprs(rma.data.of.interest)[row.names(rma.data.of.interest)%in%probe_top, ]
    status=rma.data.of.interest$Status
    df <- data.frame(values=values,status=status)
    title=paste0(comp," top ",i," probe ", probe_top, " gene ", gene_top)
    print(
      ggplot(df,aes(x=status,y=values)) +
        geom_boxplot(outlier.colour=NA,color="grey18",fill=colour) +
        stat_boxplot(geom ='errorbar', color="grey18") +
        geom_jitter(size=1,position = position_jitter(width=0.3)) +
        labs(title=title) +
        theme_bw() +
        theme(legend.position="none",axis.title=element_blank())
    )
  }
}
```

```{r boxplot, eval=T, echo=F, message=F, warning=F, fig.height=4, fig.width=4.5}
topgene_boxplot_func(tb=res[1:6,])
```


### Heatmap for Top 200 Differentially Expressed Genes

```{r heatmap_utility, eval=T, echo=F}
# The heatmap_topgene_func function for top gene heatmap plots
heatmap_topgene_func <- function(tb, topnum=200, colour_status_list, colour_status, main="") { # colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  top.rma <- rma.data.of.interest[row.names(rma.data.of.interest)%in%tb[1:topnum,"ID"],] # plot heatmap for top 200 genes
  array_name <- shortname_func(colnames(exprs(top.rma))) # shorten the sample id
  heatmap.2(na.omit(exprs(top.rma)), col=viridis(256, option="B"),
    ColSideColors=colour_status_list, # use predefined colour_status_list, assign colors to status
    labCol=array_name,labRow = "", # take out gene probe id
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow=1,cexCol=1,
    keysize=1.5,key.title=NA,key.xlab="Gene Expression Values",key.ylab="Counts",
    main=main)
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.8) # use predifined colour_status
}
```


```{r heatmap1, eval=T, echo=F, fig.height=10, fig.width=12}
heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_status_list, colour_status=colour_status, main="Gene expression heatmap by comparison status")
```

```{r heatmap2, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  heatmap_topgene_func(tb=res, topnum=200, colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Gene expression heatmap by scan date")
}
```

### Heatmap for Sample Correlation

```{r corplot_utility, eval=T, echo=F, fig.height=10, fig.width=12}
# The corplot_func function plots correlation between samples
corplot_func <- function(m, colour_status_list, colour_status, main="") {  # m: correlation matrix, colour_status_list: color assigned to each sample; colour_status: colour vector for the legend plot
  m <- cor(na.omit(m)) # compute correlation matrix
  # compute distance based on 1-correlation efficient
  dend = as.dendrogram(hclust(as.dist(1-m), method = "single"))
  ord = order.dendrogram(dend)
  array_name <- shortname_func(colnames(m)) # shorten the sample id
  # heatmap plot
  heatmap.2(m,Rowv=dend,Colv=dend,
    col=viridis(256,option="B"), ColSideColors=colour_status_list, RowSideColors=colour_status_list,
    labCol=array_name, labRow=array_name,
    trace="none",
    margins=c(12,20), # (bottom margin, left margin)
    cexRow = 1,cexCol = 1,
    keysize=1.5,key.title=NA,key.xlab="Dist2",key.ylab="Counts")
  legend("bottomleft",legend=names(colour_status),fill=colour_status,cex=0.6)
}
```


```{r corplot1, eval=T, echo=F, fig.height=10, fig.width=12}
corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_status_list, colour_status=colour_status, main="Correlation heatmap by comparison status")
```

```{r corplot2, eval=T, echo=F, fig.height=10, fig.width=12}
if ("ScanDate_Group"%in%names(pheno)) {
  corplot_func(m=exprs(rma.data.of.interest),colour_status_list=colour_scandate_list, colour_status=colour_scandate, main="Correlation heatmap by scan date")
}
```

### Principal Component Analysis (PCA)

```{r pca_utility, eval=T, echo=F, warning=F, message=F, results="asis"}
# The pcastat_func function computes principal components
pcastat_func <- function(m) {
  # obtain original expression data
  raw.data.pca <- na.omit(apply(m,2,function(x)replace(x,is.infinite(x),NA))) # replace infinite values to NAs and omit NAs
  # As scale function divides by the variance, the probe with the expression sd=0 across samples must be removed.
  sd <- apply(raw.data.pca,1,sd)
  raw.data.pca <- raw.data.pca[!sd==0,]
  # compute pcs
  pca <- prcomp(t(raw.data.pca), retx = TRUE, center = TRUE, scale = TRUE)
  pc <- data.frame(pca$x)
  # compute variance explained by each PC
  vars <- pca$sdev^2
  pcs <- t(pc)
  pvars <- vars*100.0/sum(vars) # proportion of variance (%) explained by each PC
  cumsum_pvars <- cumsum(pvars) # Cumulative Proportion of Variance (%)
  if (nrow(pcs)>10) {nres <- 10} else {nres=nrow(pcs)} # select top 10 PCs if number of PCs >10
  res <- data.frame(rownames(pcs),pvars,cumsum_pvars)[1:nres,]
  names(res) <- c("PC","Proportion of Variance (%)","Cumulative Proportion of Variance (%)")
  return(list(tb=res,pc=pc))
}

# The pcaplot_func creates plots for pc1 and pc2
pcaplot_func <- function(oligo.data, pc, group_var, legend) { # group_var: column name for a specific group; legend: legend name
  df <- data.frame(
    PC1=pc$PC1,
    PC2=pc$PC2,
    group=pData(oligo.data)[,group_var]
  )
  i=length(levels(pData(oligo.data)[,group_var]))
  group_col <- colours[1:i]
  names(group_col) <- levels(pData(oligo.data)[,group_var]) # colour to corresponding group for plot
  ggplot(df,aes(PC1,PC2,color=group)) + geom_point() +
    theme_bw() +
    scale_color_manual(legend,values=group_col,na.value="grey")
}

# The pca_func function generates multiple pca plots for scan date, disease, treatment, and subject
pca_func <- function(oligo.data, pc) {
  group_vars=c("ScanDate_Group", "Status", "Subject")
  legends=c("ScanDate_Group", "Status", "Donor")
  idx_exist=c(1:length(group_vars))[group_vars%in%names(pData(oligo.data))] # obtain index of existing variables
  plot_list=list() # store plots in a list
  for (i in idx_exist) {
    group_var=group_vars[i]
    legend=legends[i]
    nlevel=nlevels(pData(oligo.data)[,group_var]) # levels of the variable
    if (group_var=="ScanDate_Group"|(nlevel>=2&nlevel<=10)) {
      if (group_var=="Status") {
        plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)+scale_color_manual(legend,values=colour_status,na.value="grey") # assign colour to comparison stauts
      } else {plot_list[[group_var]]=pcaplot_func(oligo.data=oligo.data, pc=pc, group_var=group_var,legend=legend)}
    }
  }
  return(plot_list)
}
```

1. Compute PCs and variance explained by the first 10 PCs

```{r pca_tb, eval=T, echo=F, warning=F, message=F, results="asis"}
res_pca <- pcastat_func(m=exprs(rma.data.of.interest))
pandoc.table(res_pca$tb, split.tables=Inf, caption="Variance explained")
```

2. PCA plots

PCA plots are generated using the first two principle components colored by known factors (e.g. comparison status, donors and scan dates), visualizing similarities between arrays and these similarities' correlation to batch effects.

```{r pca_plot, eval=T, echo=F, message=F, warning=F}
plot_list=pca_func(oligo.data=rma.data.of.interest, pc=res_pca$pc)
for (i in plot_list) {print(i)}
```


#### Session information

```{r sessioninfo, eval=T, echo=F}
pander(sessionInfo())
```